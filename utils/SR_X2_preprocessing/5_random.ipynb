{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해상도를 두배 증가시킨 이미지를 최대한 겹치지않게 random으로 5개 crop하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image, crop_size, existing_crops):\n",
    "    img_width, img_height = image.size\n",
    "    crop_width, crop_height = crop_size\n",
    "    max_attempts = 100\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        x_offset = random.randint(0, img_width - crop_width)\n",
    "        y_offset = random.randint(0, img_height - crop_height)\n",
    "        new_crop = (x_offset, y_offset, crop_width, crop_height)\n",
    "\n",
    "        if not any(is_overlapping(new_crop, existing_crop) for existing_crop in existing_crops):\n",
    "            return new_crop\n",
    "\n",
    "    return new_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(crop1, crop2, iou_threshold=0.1):\n",
    "    x1, y1, w1, h1 = crop1\n",
    "    x2, y2, w2, h2 = crop2\n",
    "\n",
    "    xa = max(x1, x2)\n",
    "    ya = max(y1, y2)\n",
    "    xb = min(x1 + w1, x2 + w2)\n",
    "    yb = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    inter_width = max(0, xb - xa)\n",
    "    inter_height = max(0, yb - ya)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    crop1_area = w1 * h1\n",
    "    crop2_area = w2 * h2\n",
    "\n",
    "    iou = inter_area / (crop1_area + crop2_area - inter_area)\n",
    "    return iou > iou_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_annotations_for_subimage(annotations, subimg_info, img_id):\n",
    "    updated_annotations = []\n",
    "    x_offset, y_offset, subimg_width, subimg_height = subimg_info\n",
    "\n",
    "    for ann in annotations:\n",
    "        x, y, width, height = ann['bbox']\n",
    "\n",
    "        x1 = max(x, x_offset)\n",
    "        y1 = max(y, y_offset)\n",
    "        x2 = min(x + width, x_offset + subimg_width)\n",
    "        y2 = min(y + height, y_offset + subimg_height)\n",
    "\n",
    "        if x1 < x2 and y1 < y2:\n",
    "            new_x = x1 - x_offset\n",
    "            new_y = y1 - y_offset\n",
    "            new_width = x2 - x1\n",
    "            new_height = y2 - y1\n",
    "\n",
    "            if new_width > 0 and new_height > 0:\n",
    "                updated_ann = ann.copy()\n",
    "                updated_ann['bbox'] = [new_x, new_y, new_width, new_height]\n",
    "                updated_ann['image_id'] = img_id\n",
    "                \n",
    "                if 'segmentation' in updated_ann:\n",
    "                    updated_segmentation = []\n",
    "                    for seg in updated_ann['segmentation']:\n",
    "                        new_seg = []\n",
    "                        for i in range(0, len(seg), 2):\n",
    "                            new_x = seg[i] - x_offset\n",
    "                            new_y = seg[i+1] - y_offset\n",
    "                            if 0 <= new_x <= subimg_width and 0 <= new_y <= subimg_height:\n",
    "                                new_seg.extend([new_x, new_y])\n",
    "                        if len(new_seg) >= 6:\n",
    "                            updated_segmentation.append(new_seg)\n",
    "                    updated_ann['segmentation'] = updated_segmentation\n",
    "\n",
    "                updated_annotations.append(updated_ann)\n",
    "    \n",
    "    return updated_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing\n",
    "original_folder = '/data/ephemeral/home/dataset/'\n",
    "sr_folder = '/data/ephemeral/home/EDSR-PyTorch/experiment/test/results-Demo/'\n",
    "annotation_file = '/data/ephemeral/home/dataset/train.json'\n",
    "subimgs_path = '/data/ephemeral/home/dataset/scale_x2_random'\n",
    "updated_annotation_path = '/data/ephemeral/home/dataset/train_random_x2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotation_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize new images and annotations lists\n",
    "new_images = []\n",
    "new_annotations = []\n",
    "new_img_id = max([img['id'] for img in data['images']]) + 1\n",
    "\n",
    "# Create COCO object and get image file list\n",
    "coco = COCO(annotation_file)\n",
    "image_files = os.listdir(os.path.join(sr_folder, 'train'))\n",
    "\n",
    "crop_size = (1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(image_files, desc=\"Processing images\"):\n",
    "    img_id = int(idx.split('_')[0])\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    \n",
    "    # Load SR image (2x size)\n",
    "    I = Image.open(os.path.join(sr_folder, f\"{img_info['file_name'].split('.')[0]}_x2_SR.png\"))\n",
    "    img_width, img_height = I.size\n",
    "\n",
    "    # Get original annotations\n",
    "    annIds = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "    original_anns = coco.loadAnns(annIds)\n",
    "\n",
    "    # Adjust original annotation coordinates for SR image (2x)\n",
    "    for ann in original_anns:\n",
    "        ann['bbox'] = [coord * 2 for coord in ann['bbox']]\n",
    "\n",
    "    existing_crops = []\n",
    "\n",
    "    # Perform 5 random crops for each image\n",
    "    for i in range(5):\n",
    "        crop_info = random_crop(I, crop_size, existing_crops)\n",
    "        updated_anns = update_annotations_for_subimage(original_anns, crop_info, new_img_id)\n",
    "\n",
    "        # Save cropped image and add new annotations\n",
    "        x_offset, y_offset, subimg_width, subimg_height = crop_info\n",
    "        subimg = I.crop((x_offset, y_offset, x_offset + subimg_width, y_offset + subimg_height))\n",
    "\n",
    "        subimg_filename = f\"{img_info['file_name'].split('.')[0]}_random_crop_{i}_x2_SR.png\"\n",
    "        \n",
    "        if updated_anns:\n",
    "            new_img = {\n",
    "                \"width\": subimg_width,\n",
    "                \"height\": subimg_height,\n",
    "                \"file_name\": subimg_filename,\n",
    "                \"date_captured\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"id\": new_img_id\n",
    "            }\n",
    "            new_images.append(new_img)\n",
    "            new_annotations.extend(updated_anns)\n",
    "\n",
    "            # Save subimg only if it contains bboxes\n",
    "            subimg.save(os.path.join(subimgs_path, subimg_filename))\n",
    "        \n",
    "            new_img_id += 1\n",
    "\n",
    "        existing_crops.append(crop_info)\n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update annotation file\n",
    "data['images'].extend(new_images)\n",
    "data['annotations'].extend(new_annotations)\n",
    "\n",
    "with open(updated_annotation_path, 'w') as file:\n",
    "    json.dump(data, file, indent=2)\n",
    "\n",
    "print(\"Annotation file updated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
